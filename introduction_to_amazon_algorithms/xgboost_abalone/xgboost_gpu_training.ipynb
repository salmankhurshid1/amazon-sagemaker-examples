{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Training for XGBoost\n",
    "\n",
    "This notebook shows usage of GPU for XGBoost training. Below we show how GPU instances can be used for the 'algorithm mode' training methods with the XGBoost container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will perform XGBoost training as described [here](). See the original notebook for more details on the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "Ensuring the latest sagemaker sdk is installed. For a major version upgrade, there might be some apis that may get deprecated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU awscli boto3 sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup variables and define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import io\n",
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "import urllib\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "# S3 bucket for saving code and model artifacts.\n",
    "# Feel free to specify a different bucket here if you wish.\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "prefix = 'sagemaker/DEMO-xgboost-spot'\n",
    "# customize to your bucket where you have would like to store the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Load the dataset\n",
    "FILE_DATA = 'abalone'\n",
    "urllib.request.urlretrieve(\"https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/regression/abalone\", FILE_DATA)\n",
    "sagemaker.Session().upload_data(FILE_DATA, bucket=bucket, key_prefix=prefix+'/train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining the latest XGBoost container\n",
    "We obtain the new container by specifying the framework version (1.1-1). This version specifies the upstream XGBoost framework version (1.1) and an additional SageMaker version (1). If you have an existing XGBoost workflow based on the previous (0.72) container, this would be the only change necessary to get the same workflow working with the new container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "container = get_image_uri(region, 'xgboost', '1.1-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the XGBoost model using GPU\n",
    "\n",
    "After setting training parameters, we kick off training, and poll for status until training is completed, which in this example, takes few minutes.\n",
    "\n",
    "To run our training job on SageMaker, we construct a sagemaker.xgboost.estimator.XGBoost estimator, which accepts several constructor arguments:\n",
    "\n",
    "* __container__: The container obtained in the previous step.\n",
    "* __role__: Role ARN\n",
    "* __hyperparameters__: A dictionary passed to the train function as hyperparameters.\n",
    "* __train_instance_type__ *(optional)*: The type of SageMaker instances for training.\n",
    "* __sagemaker_session__ *(optional)*: The session used to train on Sagemaker.\n",
    "\n",
    "To run an XGBoost training job with GPU support, we have to set the parameter, `tree_method` to `gpu_hist` to utilize the full benefits of GPUs. Alongside this, we also have to use a GPU instance for our training, and for our experiment we will utilize `ml.p3.2xlarge`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "        \"max_depth\":\"5\",\n",
    "        \"eta\":\"0.2\",\n",
    "        \"gamma\":\"4\",\n",
    "        \"min_child_weight\":\"6\",\n",
    "        \"subsample\":\"0.7\",\n",
    "        \"silent\":\"0\",\n",
    "        \"tree_method\":\"gpu_hist\",\n",
    "        \"objective\":\"reg:squarederror\",\n",
    "        \"num_round\":\"10\"}\n",
    "\n",
    "instance_type_gpu = 'ml.p3.2xlarge'\n",
    "output_path = 's3://{}/{}/{}/output'.format(bucket, prefix, 'abalone-xgb')\n",
    "content_type = \"libsvm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "job_name = 'DEMO-xgboost-spot-' + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "print(\"Training job\", job_name)\n",
    "\n",
    "train_use_spot_instances = False\n",
    "train_max_run = 60*30\n",
    "\n",
    "estimator = sagemaker.estimator.Estimator(container, \n",
    "                                          role, \n",
    "                                          hyperparameters=hyperparameters,\n",
    "                                          train_instance_count=1,\n",
    "                                          train_instance_type=instance_type_gpu, \n",
    "                                          train_volume_size=10,\n",
    "                                          output_path=output_path, \n",
    "                                          sagemaker_session=sagemaker.Session(),\n",
    "                                          train_use_spot_instances=train_use_spot_instances, \n",
    "                                          train_max_run=train_max_run\n",
    "                                         );\n",
    "train_input = sagemaker.s3_input(s3_data='s3://{}/{}/{}'.format(bucket, prefix, 'train'), content_type='libsvm')\n",
    "estimator.fit({'train': train_input}, job_name=job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU Training time\n",
    "Towards the end of the job you should see two lines of output printed:\n",
    "\n",
    "- `Training seconds: X` : This is the actual compute-time your training job spent\n",
    "- `Billable seconds: Y` : This is the time you will be billed for(applicable when spot instances are used)\n",
    "\n",
    "`Billable seconds` is the total training time using a GPU instance. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
